%% PPGCC - CCN - UFPI

%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/
%% Exemplo de arquivo .bib a ser utilizado para gerar a Biliografia

%% Quando for no Google Scholar, clique em bibtex na citação e copie o código pra colar aqui


@article{Zhao2021DeepLF,
  title={Deep learning for COVID-19 detection based on CT images},
  author={Wentao Zhao and Wei Jiang and Xinguo Qiu},
  journal={Scientific Reports},
  year={2021},
  volume={11}
}

@misc{readingMachine,
    author={Gustav Tauschek},
    howpublished={27 maio 1929},
    number={US2026330A},
    title={Reading machine},
    year={1929}
}

@article{DetcRecogWild,
  title={Text Detection and Recognition in the Wild: A Review},
  author={Z. Raisi and Mohamed A. Naiel and Paul W. Fieguth and Steven Wardell and John S. Zelek},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.04305}
}

@article{StrDlEra,
  title={Scene Text Detection and Recognition: The Deep Learning Era},
  author={Shangbang Long and Xin He and Cong Yao},
  journal={International Journal of Computer Vision},
  year={2020},
  volume={129},
  pages={161-184}
}

@inproceedings{CRAFT,
  title={Character Region Awareness for Text Detection},
  author={Baek, Youngmin and Lee, Bado and Han, Dongyoon and Yun, Sangdoo and Lee, Hwalsuk},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={9365--9374},
  year={2019}
}

@inproceedings{UNET,
  title={U-Net: Convolutional Networks for Biomedical Image Segmentation},
  author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
  booktitle={MICCAI},
  year={2015}
}

@article{SynthText,
  title={Synthetic Data for Text Localisation in Natural Images},
  author={Ankush Gupta and Andrea Vedaldi and Andrew Zisserman},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={2315-2324}
}

@Article{WatershedOverview,
    AUTHOR = {Kornilov, Anton S. and Safonov, Ilia V.},
    TITLE = {An Overview of Watershed Algorithm Implementations in Open Source Libraries},
    JOURNAL = {Journal of Imaging},
    VOLUME = {4},
    YEAR = {2018},
    NUMBER = {10},
    ARTICLE-NUMBER = {123},
    URL = {https://www.mdpi.com/2313-433X/4/10/123},
    ISSN = {2313-433X},
    ABSTRACT = {Watershed is a widespread technique for image segmentation. Many researchers apply the method implemented in open source libraries without a deep understanding of its characteristics and limitations. In the review, we describe benchmarking outcomes of six open-source marker-controlled watershed implementations for the segmentation of 2D and 3D images. Even though the considered solutions are based on the same algorithm by flooding having O(n)computational complexity, these implementations have significantly different performance. In addition, building of watershed lines grows processing time. High memory consumption is one more bottleneck for dealing with huge volumetric images. Sometimes, the usage of more optimal software is capable of mitigating the issues with the long processing time and insufficient memory space. We assume parallel processing is capable of overcoming the current limitations. However, the development of concurrent approaches for the watershed segmentation remains a challenging problem.},
    DOI = {10.3390/jimaging4100123}
}

@article{VGG,
  title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author={Karen Simonyan and Andrew Zisserman},
  journal={CoRR},
  year={2015},
  volume={abs/1409.1556}
}

@article{CRNN,
  title={An End-to-End Trainable Neural Network for Image-Based Sequence Recognition and Its Application to Scene Text Recognition},
  author={Baoguang Shi and Xiang Bai and Cong Yao},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2017},
  volume={39},
  pages={2298-2304}
}

@article{STN,
  author    = {Max Jaderberg and
               Karen Simonyan and
               Andrew Zisserman and
               Koray Kavukcuoglu},
  title     = {Spatial Transformer Networks},
  journal   = {CoRR},
  volume    = {abs/1506.02025},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.02025},
  eprinttype = {arXiv},
  eprint    = {1506.02025},
  timestamp = {Mon, 13 Aug 2018 16:49:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/JaderbergSZK15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ICDAR2011,
author = {Karatzas, D. and Mestre, S. Robles and Mas, J. and Nourbakhsh, F. and Roy, P. Pratim},
title = {ICDAR 2011 Robust Reading Competition - Challenge 1: Reading Text in Born-Digital Images (Web and Email)},
year = {2011},
isbn = {9780769545202},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICDAR.2011.295},
doi = {10.1109/ICDAR.2011.295},
abstract = {This paper presents the results of the first Challenge of ICDAR 2011 Robust Reading Competition. Challenge 1 is focused on the extraction of text from born-digital images, specifically from images found in Web pages and emails. The challenge was organized in terms of three tasks that look at different stages of the process: text localization, text segmentation and word recognition. In this paper we present the results of the challenge for all three tasks, and make an open call for continuous participation outside the context of ICDAR 2011.},
booktitle = {Proceedings of the 2011 International Conference on Document Analysis and Recognition},
pages = {1485–1490},
numpages = {6},
keywords = {segmentation, born-digital, localization, text extraction, recognition, Web images, email images},
series = {ICDAR '11}
}

@INPROCEEDINGS{ICDAR2013,
  author={Karatzas, Dimosthenis and Shafait, Faisal and Uchida, Seiichi and Iwamura, Masakazu and Bigorda, Lluis Gomez i and Mestre, Sergi Robles and Mas, Joan and Mota, David Fernandez and Almazàn, Jon Almazàn and de las Heras, Lluís Pere},
  booktitle={2013 12th International Conference on Document Analysis and Recognition}, 
  title={ICDAR 2013 Robust Reading Competition}, 
  year={2013},
  volume={},
  number={},
  pages={1484-1493},
  doi={10.1109/ICDAR.2013.221}
  }
  
  @article{Docker,
  title={Docker: lightweight linux containers for consistent development and deployment},
  author={Merkel, Dirk},
  journal={Linux journal},
  volume={2014},
  number={239},
  pages={2},
  year={2014}
}

@inproceedings{MSER,
  title={A Method for Text Localization and Recognition in Real-World Images},
  author={Luk{\'a}s Neumann and Jiri Matas},
  booktitle={ACCV},
  year={2010}
}

@article{SWT,
  title={Detecting text in natural scenes with stroke width transform},
  author={Boris Epshtein and Eyal Ofek and Yonatan Wexler},
  journal={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  year={2010},
  pages={2963-2970}
}

@article{WhatIsWrongSTR,
  title={What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis},
  author={Jeonghun Baek and Geewook Kim and Junyeop Lee and Sungrae Park and Dongyoon Han and Sangdoo Yun and Seong Joon Oh and Hwalsuk Lee},
  journal={2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2019},
  pages={4714-4722}
}

@article{GoogleLowLight,
  title={Handheld mobile photography in very low light},
  author={Orly Liba and K. V. V. Murthy and Yun-Ta Tsai and Tim Brooks and Tianfan Xue and Nikhil Karnad and Qiurui He and Jonathan T. Barron and Dillon Sharlet and Ryan Geiss and Samuel W. Hasinoff and Yael Pritch and Marc Levoy},
  journal={ACM Transactions on Graphics (TOG)},
  year={2019},
  volume={38},
  pages={1 - 16}
}

@article{GooglePortrait,
  title={Synthetic depth-of-field with a single-camera mobile phone},
  author={Neal Wadhwa and Rahul Garg and David E. Jacobs and Bryan E. Feldman and Nori Kanazawa and Robert E. Carroll and Yair Movshovitz-Attias and Jonathan T. Barron and Yael Pritch and Marc Levoy},
  journal={ACM Transactions on Graphics (TOG)},
  year={2018},
  volume={37},
  pages={1 - 13}
}

@article{DeepLearningATA,
  title={A survey on deep learning: Algorithms, techniques, and applications},
  author={Pouyanfar, Samira and Sadiq, Saad and Yan, Yilin and Tian, Haiman and Tao, Yudong and Reyes, Maria Presa and Shyu, Mei-Ling and Chen, Shu-Ching and Iyengar, Sundaraja S},
  journal={ACM Computing Surveys (CSUR)},
  volume={51},
  number={5},
  pages={1--36},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{SurveyImagery,
author = {Ye, Qixiang and Doermann, David},
year = {2015},
month = {06},
pages = {},
title = {Text Detection and Recognition in Imagery: A Survey},
volume = {37},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
doi = {10.1109/TPAMI.2014.2366765}
}

@article{MLDLVision,
title = {Machine Learning and Deep Learning Applications-A Vision},
journal = {Global Transitions Proceedings},
volume = {2},
number = {1},
pages = {24-28},
year = {2021},
note = {1st International Conference on Advances in Information, Computing and Trends in Data Engineering (AICDE - 2020)},
issn = {2666-285X},
doi = {https://doi.org/10.1016/j.gltp.2021.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S2666285X21000042},
author = {Neha Sharma and Reecha Sharma and Neeru Jindal},
keywords = {Deep neural learning (DL), Machine Learning (ML), Machine intelligence (artificial intelligence-AL)},
abstract = {The application of artificial intelligence is machine learning which is one of the current topics in the computer field as well as for the new COVID-19 pandemic. Researchers have given a lot of input to enhance the precision of machine learning algorithms and lot of work is carried out rapidly to enhance the intelligence of machines. Learning, a natural process in human behaviour that also becomes a vital part of machines as well. Besides this, another concept of deep learning comes to play its major role. Deep neural network (deep learning) is a subgroup of machine learning. Deep learning had been analysed and implemented in various applications and had shown remarkable results thus this field needs wider exploration which can be helpful for further real-world applications. The main objective of this paper is to provide insight survey for machine learning along with deep learning applications in various domains. Also, some applications with new normal COVID-19 blues. A review on already present applications and currently going on applications in several domains, for machine learning along with deep neural learning are exemplified.}
}

@article{ReviewDL,
  title={Review of deep learning: concepts, CNN architectures, challenges, applications, future directions},
  author={Laith Alzubaidi and Jinglan Zhang and Amjad J. Humaidi and Ayad Al-dujaili and Ye Duan and Omran Al-Shamma and Jesus Santamar{\'i}a and Mohammed Abdulraheem Fadhel and Muthana Al-Amidie and Laith Farhan},
  journal={Journal of Big Data},
  year={2021},
  volume={8}
}

@article{IntoMLNNDL,
    author = {Choi, Rene Y. and Coyner, Aaron S. and Kalpathy-Cramer, Jayashree and Chiang, Michael F. and Campbell, J. Peter},
    title = "{Introduction to Machine Learning, Neural Networks, and Deep Learning}",
    journal = {Translational Vision Science \& Technology},
    volume = {9},
    number = {2},
    pages = {14-14},
    year = {2020},
    month = {02},
    abstract = "{   To present an overview of current machine learning methods and their use in medical research, focusing on select machine learning techniques, best practices, and deep learning.    A systematic literature search in PubMed was performed for articles pertinent to the topic of artificial intelligence methods used in medicine with an emphasis on ophthalmology.    A review of machine learning and deep learning methodology for the audience without an extensive technical computer programming background.    Artificial intelligence has a promising future in medicine; however, many challenges remain.    The aim of this review article is to provide the nontechnical readers a layman's explanation of the machine learning methods being used in medicine today. The goal is to provide the reader a better understanding of the potential and challenges of artificial intelligence within the field of medicine.  }",
    issn = {2164-2591},
    doi = {10.1167/tvst.9.2.14},
    url = {https://doi.org/10.1167/tvst.9.2.14},
    eprint = {https://arvojournals.org/arvo/content\_public/journal/tvst/938366/i2164-2591-226-2-2007.pdf},
}


@InProceedings{FCN,
author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
title = {Fully Convolutional Networks for Semantic Segmentation},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}

@article{TransfLearn,
  author    = {Chuanqi Tan and
               Fuchun Sun and
               Tao Kong and
               Wenchang Zhang and
               Chao Yang and
               Chunfang Liu},
  title     = {A Survey on Deep Transfer Learning},
  journal   = {CoRR},
  volume    = {abs/1808.01974},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.01974},
  eprinttype = {arXiv},
  eprint    = {1808.01974},
  timestamp = {Mon, 18 Jan 2021 14:59:43 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-01974.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{1DCNN,
title = {1D convolutional neural networks and applications: A survey},
journal = {Mechanical Systems and Signal Processing},
volume = {151},
pages = {107398},
year = {2021},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2020.107398},
url = {https://www.sciencedirect.com/science/article/pii/S0888327020307846},
author = {Serkan Kiranyaz and Onur Avci and Osama Abdeljaber and Turker Ince and Moncef Gabbouj and Daniel J. Inman},
keywords = {Artificial Neural Networks, Machine learning, Deep learning, Convolutional neural networks, Structural health monitoring, Condition monitoring, Arrhythmia detection and identification, Fault detection, Structural damage detection},
abstract = {During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap.}
}

@article{ActvFunc,
  author    = {Chigozie Nwankpa and
               Winifred Ijomah and
               Anthony Gachagan and
               Stephen Marshall},
  title     = {Activation Functions: Comparison of trends in Practice and Research
               for Deep Learning},
  journal   = {CoRR},
  volume    = {abs/1811.03378},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.03378},
  eprinttype = {arXiv},
  eprint    = {1811.03378},
  timestamp = {Fri, 23 Nov 2018 12:43:51 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1811-03378.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{StanfordCNN,
    title={Convolutional Neural Networks for Visual Recognition},
    url={https://cs231n.github.io/convolutional-networks/},
    year={2021}
}


@article{IntroCNN,
  author    = {Keiron O'Shea and
               Ryan Nash},
  title     = {An Introduction to Convolutional Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1511.08458},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.08458},
  eprinttype = {arXiv},
  eprint    = {1511.08458},
  timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/OSheaN15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ResNet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  eprinttype = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{GooLeNet,
  author    = {Christian Szegedy and
               Wei Liu and
               Yangqing Jia and
               Pierre Sermanet and
               Scott E. Reed and
               Dragomir Anguelov and
               Dumitru Erhan and
               Vincent Vanhoucke and
               Andrew Rabinovich},
  title     = {Going Deeper with Convolutions},
  journal   = {CoRR},
  volume    = {abs/1409.4842},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.4842},
  eprinttype = {arXiv},
  eprint    = {1409.4842},
  timestamp = {Mon, 13 Aug 2018 16:48:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SzegedyLJSRAEVR14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ILSVRC,
    Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
    Title = {{ImageNet Large Scale Visual Recognition Challenge}},
    Year = {2015},
    journal   = {International Journal of Computer Vision (IJCV)},
    doi = {10.1007/s11263-015-0816-y},
    volume={115},
    number={3},
    pages={211-252}
}

@inproceedings{ImageNet,
    AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
    TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
    BOOKTITLE = {CVPR09},
    YEAR = {2009},
    BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"
}

@ARTICLE{BRNN,
  author={Schuster, M. and Paliwal, K.K.},
  journal={IEEE Transactions on Signal Processing}, 
  title={Bidirectional recurrent neural networks}, 
  year={1997},
  volume={45},
  number={11},
  pages={2673-2681},
  doi={10.1109/78.650093}}

  @article{DRNN,
  author    = {Bo Pang and
               Kaiwen Zha and
               Hanwen Cao and
               Chen Shi and
               Cewu Lu},
  title     = {Deep {RNN} Framework for Visual Sequential Applications},
  journal   = {CoRR},
  volume    = {abs/1811.09961},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.09961},
  eprinttype = {arXiv},
  eprint    = {1811.09961},
  timestamp = {Fri, 30 Nov 2018 12:44:28 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1811-09961.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{LSTM,
author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
year = {1997},
month = {12},
pages = {1735-80},
title = {Long Short-term Memory},
volume = {9},
journal = {Neural computation},
doi = {10.1162/neco.1997.9.8.1735}
}

@article{VanishGrad,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
  journal={IEEE transactions on neural networks},
  volume={5},
  number={2},
  pages={157--166},
  year={1994},
  publisher={IEEE}
}

@misc{StanfordRNN,
    url={https://cs231n.github.io/rnn/},
    year={2021},
    title={Introduction to RNN},
    author={Baimyrza, Darkhan}
}

@article{Attention,
  title={Neural Machine Translation by Jointly Learning to Align and Translate},
  author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  journal={CoRR},
  year={2015},
  volume={abs/1409.0473}
}

@inproceedings{CTC,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}

@inproceedings{HOG,
author = {Dalal, Navneet and Triggs, Bill},
title = {Histograms of Oriented Gradients for Human Detection},
year = {2005},
isbn = {0769523722},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CVPR.2005.177},
doi = {10.1109/CVPR.2005.177},
abstract = {We study the question of feature sets for robust visual object recognition, adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of Histograms of Oriented Gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
booktitle = {Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Volume 1 - Volume 01},
pages = {886–893},
numpages = {8},
series = {CVPR '05}
}

@inproceedings{SSD,
  title={Ssd: Single shot multibox detector},
  author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C},
  booktitle={European conference on computer vision},
  pages={21--37},
  year={2016},
  organization={Springer}
}

@inproceedings{YOLO,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}

@InProceedings{RCNN,
author = {Girshick, Ross},
title = {Fast R-CNN},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}

@article{TxtBoxPlus,
  title={Textboxes++: A single-shot oriented scene text detector},
  author={Liao, Minghui and Shi, Baoguang and Bai, Xiang},
  journal={IEEE transactions on image processing},
  volume={27},
  number={8},
  pages={3676--3690},
  year={2018},
  publisher={IEEE}
}

@inproceedings{TxtBox,
  title={Textboxes: A fast text detector with a single deep neural network},
  author={Liao, Minghui and Shi, Baoguang and Bai, Xiang and Wang, Xinggang and Liu, Wenyu},
  booktitle={Thirty-first AAAI conference on artificial intelligence},
  year={2017}
}
@inproceedings{Seglink,
  title={Detecting oriented text in natural images by linking segments},
  author={Shi, Baoguang and Bai, Xiang and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2550--2558},
  year={2017}
}
@inproceedings{EAST,
  title={East: an efficient and accurate scene text detector},
  author={Zhou, Xinyu and Yao, Cong and Wen, He and Wang, Yuzhi and Zhou, Shuchang and He, Weiran and Liang, Jiajun},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={5551--5560},
  year={2017}
}
@inproceedings{MOTextFCN,
  title={Multi-oriented text detection with fully convolutional networks},
  author={Zhang, Zheng and Zhang, Chengquan and Shen, Wei and Yao, Cong and Liu, Wenyu and Bai, Xiang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4159--4167},
  year={2016}
}
@article{STDChannel,
  title={Scene text detection via holistic, multi-channel prediction},
  author={Yao, Cong and Bai, Xiang and Sang, Nong and Zhou, Xinyu and Zhou, Shuchang and Cao, Zhimin},
  journal={arXiv preprint arXiv:1606.09002},
  year={2016}
}

@inproceedings{pixellink,
  title={Pixellink: Detecting scene text via instance segmentation},
  author={Deng, Dan and Liu, Haifeng and Li, Xuelong and Cai, Deng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}
@inproceedings{textsnake,
  title={Textsnake: A flexible representation for detecting text of arbitrary shapes},
  author={Long, Shangbang and Ruan, Jiaqiang and Zhang, Wenjie and He, Xin and Wu, Wenhao and Yao, Cong},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={20--36},
  year={2018}
}
@misc{KPN,
  doi = {10.48550/ARXIV.2203.06410},
  url = {https://arxiv.org/abs/2203.06410},
  author = {Zhang, Shi-Xue and Zhu, Xiaobin and Hou, Jie-Bo and Yang, Chun and Yin, Xu-Cheng},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Kernel Proposal Network for Arbitrary Shape Text Detection},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}
@misc{DEER,
  doi = {10.48550/ARXIV.2203.05122},
  url = {https://arxiv.org/abs/2203.05122},
  author = {Kim, Seonghyeon and Shin, Seung and Kim, Yoonsik and Cho, Han-Cheol and Kil, Taeho and Surh, Jaeheung and Park, Seunghyun and Lee, Bado and Baek, Youngmin},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {DEER: Detection-agnostic End-to-End Recognizer for Scene Text Spotting},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{Transformer,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  eprinttype = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@INPROCEEDINGS{ICDAR2015,
  author={Karatzas, Dimosthenis and Gomez-Bigorda, Lluis and Nicolaou, Anguelos and Ghosh, Suman and Bagdanov, Andrew and Iwamura, Masakazu and Matas, Jiri and Neumann, Lukas and Chandrasekhar, Vijay Ramaseshan and Lu, Shijian and Shafait, Faisal and Uchida, Seiichi and Valveny, Ernest},
  booktitle={2015 13th International Conference on Document Analysis and Recognition (ICDAR)}, 
  title={ICDAR 2015 competition on Robust Reading}, 
  year={2015},
  volume={},
  number={},
  pages={1156-1160},
  doi={10.1109/ICDAR.2015.7333942}}
  @INPROCEEDINGS{ICDAR2017,
  author={Iwamura, Masakazu and Morimoto, Naoyuki and Tainaka, Keishi and Bazazian, Dena and Gomez, Lluis and Karatzas, Dimosthenis},
  booktitle={2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)}, 
  title={ICDAR2017 Robust Reading Challenge on Omnidirectional Video}, 
  year={2017},
  volume={01},
  number={},
  pages={1448-1453},
  doi={10.1109/ICDAR.2017.236}}
  @INPROCEEDINGS{ICDAR2003,
  author={Lucas, S.M. and Panaretos, A. and Sosa, L. and Tang, A. and Wong, S. and Young, R.},
  booktitle={Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.}, 
  title={ICDAR 2003 robust reading competitions}, 
  year={2003},
  volume={},
  number={},
  pages={682-687},
  doi={10.1109/ICDAR.2003.1227749}}